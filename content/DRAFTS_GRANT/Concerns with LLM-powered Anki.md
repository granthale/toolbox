---
author: Grant
draft: "true"
---
- [[Abusing LLMs can handicap our critical thinking ability]]
- Robs us of valuable opportunity to grapple with material and come up with questions ourselves
- Hallucinations exist, making potential answers less trustworthy. Some believe that this could keep us sharper.
- [[How can we direct LLM-powered SRS towards what we want to learn about?]] How can we redirect it in the direction that we want to go?

Designing a system will be about making the proper tradeoffs.