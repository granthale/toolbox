---
author: Grant
tags:
  - seed
---
In thinking about [[Desirable features for an LLM-powered Anki]], **I'd like to see Anki gently push the boundaries of what we know**.

**[@Anton](https://twitter.com/atroyn/status/1565641497524985857)** describes it like this:
>“I tell you something I want to learn about, and you generate a spaced repetition program to learn that thing which adapts to my real measured progress. a.i generated quantum country”

This is different from a typical Anki workflow:
1. Read interesting material → think through prompts → input to Anki
2. Review Anki → further questions often come up → input to Anki

This classic model relies on curiosity and agency, both things that benefit from consistent use, but also the highest-energy muscles that we have.

Instead, Anki could act as the wrist-straps for deadlifts, augmenting certain muscles (in this case, question asking and content generation) while training targeted muscles (knowledge acquisition and memory).

While reliance on our own curiosity pushes our ability to ask questions and learn, it would be nice to not have to do all the heavy lifting ourselves. See [[Concerns with LLM-powered Anki]]. I envision an LLM-supported Anki continuing to ask us questions in the direction that want, akin to a tutor.

At this point, I expect human review to be essential to maintaining high quality, on-topic prompts, but our decks will be that much easier to expand.

==TODO==
Here's a starting place:

>**Q:** What are people keeping a close eye on with the GE poplars that China planted?

>**A:** Gene flow